{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Interpolation Objects in Batches with Job Arrays\n",
    "\n",
    "In this notebook we will walk through how to create interpolation objects that \n",
    "are constructed from batches of effective parameter data. This data was generated\n",
    "by batching voltage control vectors and running each batch in parallel on the HPC cluster.\n",
    "\n",
    "**NOTE:** Utilizing job arrays allows for an order of magnitude speed up when \n",
    "calcualting effective parameters.\n",
    "\n",
    "Example: Serial job took 168 hours = 7 days -> Parallel job with 10 CPUs/workers took 16.8 hours!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First change base working directory and import relevant modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "path = Path(os.getcwd())\n",
    "\n",
    "# update base working directory to QuDiPy\n",
    "if path.stem != 'QuDiPy':\n",
    "    base_dir = path.parents[1]\n",
    "    os.chdir(base_dir)\n",
    "else:\n",
    "    base_dir = path\n",
    "    \n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from qudipy.system import DotArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mimic HPC Batch Job Execution\n",
    "\n",
    "We can test how the parallel computation would take place on the cluster with multiple CPUs, but \n",
    "instead perform a local serial calculation using only one CPU. The bash script that is shown later will\n",
    "define how a python file is called in a job array compared to this toy example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy 4 Batch Example\n",
    "\n",
    "We can mimic a HPC job array by calling a python script in a for loop as follows.\n",
    "The python script requires two inputs:\n",
    "1) The current batch to evaluate\n",
    "2) The total number of batches that are to be run (in parallel on the HPC cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ Calculating batch 1/4 now ------------------\n",
      "\n",
      "g_factor evaluation: control vector=[0.2 0.1 0.4]:  92%|█████████▏| 11/12 [00:15<00:01,  1.43s/it]                       \n",
      " Warning: number of detected dots is 1 -> different from user-specified value 2. Parameters are not evaluated\n",
      "\n",
      " Warning: number of detected dots is 1 -> different from user-specified value 2. Parameters are not evaluated\n",
      "g_factor evaluation: control vector=[0.2 0.1 0.4]: 100%|██████████| 12/12 [00:16<00:00,  1.34s/it]\n",
      "Exchange HL evaluation: control vector=[0.2 0.1 0.4]:  75%|███████▌  | 9/12 [00:00<00:00, 25.28it/s]                        \n",
      " Warning: number of detected dots is 1 -> different from user-specified value 2. Parameters are not evaluated\n",
      "Exchange HL evaluation: control vector=[0.2 0.1 0.4]: 100%|██████████| 12/12 [00:00<00:00, 26.09it/s]\n",
      "Exchange HM evaluation: control vector=[0.2 0.1 0.4]:  75%|███████▌  | 9/12 [00:00<00:00, 24.26it/s]                        \n",
      " Warning: number of detected dots is 1 -> different from user-specified value 2. Parameters are not evaluated\n",
      "Exchange HM evaluation: control vector=[0.2 0.1 0.4]: 100%|██████████| 12/12 [00:00<00:00, 23.95it/s]\n",
      "\n",
      "------------------ Calculating batch 2/4 now ------------------\n",
      "\n",
      "g_factor evaluation: control vector=[0.26666667 0.1        0.4       ]: 100%|██████████| 12/12 [00:17<00:00,  1.47s/it]  \n",
      "Exchange HL evaluation: control vector=[0.26666667 0.1        0.4       ]: 100%|██████████| 12/12 [00:00<00:00, 23.00it/s]  \n",
      "Exchange HM evaluation: control vector=[0.26666667 0.1        0.4       ]: 100%|██████████| 12/12 [00:00<00:00, 21.63it/s]  \n",
      "\n",
      "------------------ Calculating batch 3/4 now ------------------\n",
      "\n",
      "g_factor evaluation: control vector=[0.33333333 0.1        0.4       ]: 100%|██████████| 12/12 [00:18<00:00,  1.55s/it]  \n",
      "Exchange HL evaluation: control vector=[0.33333333 0.1        0.4       ]: 100%|██████████| 12/12 [00:00<00:00, 23.20it/s]  \n",
      "Exchange HM evaluation: control vector=[0.33333333 0.1        0.4       ]: 100%|██████████| 12/12 [00:00<00:00, 23.98it/s]  \n",
      "\n",
      "------------------ Calculating batch 4/4 now ------------------\n",
      "\n",
      "g_factor evaluation: control vector=[0.4 0.1 0.2]:  67%|██████▋   | 8/12 [00:12<00:05,  1.48s/it]                        \n",
      " Warning: number of detected dots is 1 -> different from user-specified value 2. Parameters are not evaluated\n",
      "\n",
      " Warning: number of detected dots is 1 -> different from user-specified value 2. Parameters are not evaluated\n",
      "g_factor evaluation: control vector=[0.4 0.1 0.4]: 100%|██████████| 12/12 [00:16<00:00,  1.39s/it]                     \n",
      "Exchange HL evaluation: control vector=[0.4 0.1 0.2]:  67%|██████▋   | 8/12 [00:00<00:00, 23.20it/s]                        \n",
      " Warning: number of detected dots is 1 -> different from user-specified value 2. Parameters are not evaluated\n",
      "Exchange HL evaluation: control vector=[0.4 0.1 0.4]: 100%|██████████| 12/12 [00:00<00:00, 23.70it/s]                     \n",
      "Exchange HM evaluation: control vector=[0.4 0.1 0.2]:  50%|█████     | 6/12 [00:00<00:00, 25.99it/s]                        \n",
      " Warning: number of detected dots is 1 -> different from user-specified value 2. Parameters are not evaluated\n",
      "Exchange HM evaluation: control vector=[0.4 0.1 0.4]: 100%|██████████| 12/12 [00:00<00:00, 26.46it/s]                    \n"
     ]
    }
   ],
   "source": [
    "for idx in range(batches):\n",
    "    batch = idx + 1 # too mimic hpc\n",
    "    %run parallel_batch_example_2QD.py {batch} {batches}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example SLURM Bash Job Submission Script and Instructions\n",
    "\n",
    "Rather than calling a python driver script to compute batches of effective parameters, \n",
    "the HPC can be leveraged to perform the batch calculations in parallel. This requires the following\n",
    "steps to be taken.\n",
    "\n",
    "1) Transfer relevant code and/or nextnano/processed data to the desired cluster. \n",
    "2) Create or modify bash scripts to be submitted as a job array using SLURM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Files to the Cluster of Interest\n",
    "\n",
    "1) In not done so already, start by requesting an account to Alliance Canada which \n",
    "will grant access to an array of clusters. Start by reading the documentation about \n",
    "selecting a desired cluster, best practices, and how to set up Globus file transfering.\n",
    "\n",
    "2) Copy code using Globus or via git clone/pull commands.\n",
    "    NOTE: Familiarity with terminal git commands is required.\n",
    "\n",
    "3) Ensure existing data sets exist in the qudipy_data_library shared data directory, \n",
    "otherwise, use Globus to transfer the desired files. Follow Globus instructions \n",
    "for file transfers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Job Submission Bash Script\n",
    "\n",
    "An example bash file will be discussed below to help speed up the learning curve \n",
    "when working on an HPC. Please read the documentation on Alliance Canada's webpage \n",
    "for a detailed description for how to perform typical HPC tasks.\n",
    "\n",
    "The example bash file used will be: \"\\Scripts\\hpc\\job_arrays\\eff_param_array_spin_2QD.sh\".\n",
    "\n",
    "NOTE: other template bash scripts for the HPC are located under \"\\Scripts\\hpc\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```#!/bin/sh\n",
    "\n",
    "#SBATCH --job-name=2QD_spin\n",
    "#SBATCH --nodes=1   \n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=10       # cpu-cores per task (>1 if multi-threaded tasks)\n",
    "#SBATCH --mem-per-cpu=10G\n",
    "#SBATCH --time=5:00:00 \n",
    "\n",
    "### email notification per batch\n",
    "#SBATCH --mail-user=<email address>\n",
    "#SBATCH --mail-type=BEGIN,END,FAIL ###,ARRAY_TASKS <- is no longer allowed for email notifications?\n",
    "\n",
    "### setup job array\n",
    "#SBATCH --array=1-10\n",
    "#SBATCH --output=2QD_spin_%A_%a.out\n",
    "\n",
    "### Setup virtual enviornment with necessary packages\n",
    "module load python/3.11.5 # check python version on cluster\n",
    "virtualenv --no-download $SLURM_TMPDIR/qudipy\n",
    "source $SLURM_TMPDIR/qudipy/bin/activate\n",
    "pip install --no-index --upgrade pip\n",
    "pip install --no-index -r QuDiPy/'QuDiPy package list'\n",
    "\n",
    "### Call the driver script\n",
    "python QuDiPy/'parallel_spin_calc_2QD.py' $SLURM_ARRAY_TASK_ID $SLURM_ARRAY_TASK_MAX > job_array_2QD_spin_batch_$SLURM_ARRAY_TASK_ID.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Effective Parameter Interpolator From Data Set Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: No effective parameter calcualtions specified. Default = \"spin\". \n",
      "\n",
      "Loading pre-calculated effective parameters: Batch 4 or 4: 100%|██████████| 4/4 [00:00<00:00, 985.27it/s]\n",
      "Effective parameter interpolator saved as:\n",
      "\t example_hpc_spin_data_size_[4 3 4]_from_[ 0.2 -0.1  0.2]_to_[0.4 0.1 0.4].pkl\n"
     ]
    }
   ],
   "source": [
    "# define input/output directories\n",
    "nav_dir = os.path.join('QuDiPy data', 'tutorials')\n",
    "processed_dir = os.path.join(base_dir, nav_dir,\n",
    "                        'processed','2QD_processed')\n",
    "nextnano_dir = os.path.join(base_dir, nav_dir,\n",
    "                                'nextnano','2QD_dotsep_60nm')\n",
    "\n",
    "# anticipated number of dots\n",
    "n_dots = 2      \n",
    "\n",
    "# define subset of control ranges to perform calcuations\n",
    "eff_interp_dims = [4,3,4]\n",
    "ctrl_vals = [np.linspace(0.2, 0.4, eff_interp_dims[0]),\n",
    "    np.linspace(-0.1, 0.1, eff_interp_dims[1]),\n",
    "    np.linspace(0.2, 0.4, eff_interp_dims[2])]\n",
    "\n",
    "# prefix for saved calculated files\n",
    "file_prefix = 'example_hpc'\n",
    "\n",
    "dots = DotArray(n_dots, ctrl_ranges=ctrl_vals, calc=False, hpc=[None, batches,'example_hpc_2QD'])\n",
    "dots.numeric(processed_dir, nextnano_dir, file_prefix)\n",
    "\n",
    "dots.construct_interpolator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qudipy",
   "language": "python",
   "name": "qudipy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
